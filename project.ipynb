{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if pyspark works\n",
    "import pyspark\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Start spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Multiclass classification IoT\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load datasets\n",
    "def load_test_data(debug=False):\n",
    "    if debug:\n",
    "        test_data = spark.read.csv(r\"./dataset/NF-ToN-IoT-v2-test.csv\", header=True, inferSchema=True).limit(200)\n",
    "        train_data = spark.read.csv(r\"./dataset/NF-ToN-IoT-v2-train.csv\", header=True, inferSchema=True).limit(600)\n",
    "    else:\n",
    "        test_data = spark.read.csv(r\"./dataset/NF-ToN-IoT-v2-test.csv\", header=True, inferSchema=True)\n",
    "        train_data = spark.read.csv(r\"./dataset/NF-ToN-IoT-v2-train.csv\", header=True, inferSchema=True)\n",
    "        \n",
    "    return test_data, train_data\n",
    "\n",
    "test_data, train_data = load_test_data(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the training dataset to verify it's loaded correctly\n",
    "train_data.show(5)\n",
    "print(train_data.count())\n",
    "\n",
    "# Display the first few rows of the testing dataset to verify it's loaded correctly\n",
    "test_data.show(5)\n",
    "print(test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the schema of the loaded data to confirm the data types of each column\n",
    "train_data.printSchema()\n",
    "test_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying missing values\n",
    "from pyspark.sql.functions import col, count, when, isnan\n",
    "\n",
    "# Count nulls and NaNs in each column\n",
    "def count_missing(data):\n",
    "    #data.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in data.columns]).show()\n",
    "    data.select([count(when(isnan(c), c)).alias(c) for c in data.columns]).show()\n",
    "\n",
    "count_missing(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying missing values\n",
    "count_missing(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is clean and doesn't have any missing values, so there's no need for further cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding\n",
    "On the dataset, which consists of network traffic data, several categorical variables could potentially benefit from encoding. The decision to apply encoding techniques depends on whether the variables are nominal (without an inherent order) or ordinal (with a specific order) and whether they are used as features in the model. \n",
    "\n",
    "After an understanding of data and the variables meaning, we considered some variables for encoding:\n",
    "- **IPV4_SRC_ADDR and IPV4_DST_ADDR** (Categorical nominal): These are IP addresses and typically should be treated as categorical.\n",
    "- **Attack** (categorical Nominal): In machine learning projects involving classification tasks, the target variable (also known as the label or response variable) is crucial as it's the outcome the model is trying to predict. On the project, the target variable consists of categorical data (e.g., text labels representing different classes), it needs to be converted into a numeric format. This conversion is essential because most machine learning algorithms require numeric input to perform calculations during model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count distinct values in IPV4_SRC_ADDR\n",
    "distinct_src_subnet_count = train_data.select(countDistinct(\"IPV4_SRC_ADDR\").alias(\"Distinct_SRC_Count\"))\n",
    "\n",
    "# Count distinct values in IPV4_DST_ADDR\n",
    "distinct_dst_subnet_count = train_data.select(countDistinct(\"IPV4_DST_ADDR\").alias(\"Distinct_DST_Subnet\"))\n",
    "\n",
    "# Show the results\n",
    "distinct_src_subnet_count.show(truncate=False)\n",
    "distinct_dst_subnet_count.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the high number of distinct values in the IPV4_ADDR column, subnet segmentation was performed to facilitate more effective encoding. This approach reduces the granularity of the data, thereby simplifying the feature space without significantly compromising the informational value of the IP addresses. Segmentation enables us to manage the high cardinality of the IP addresses, which is critical for applying machine learning techniques efficiently and effectively. By categorizing the IP addresses into their respective subnets, we can capture essential network-level behaviors while avoiding the computational complexity associated with the vast number of unique full IP addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, split\n",
    "\n",
    "def add_subnet_columns(data):\n",
    "    # Add a new column for the subnet (first two octets) for source and destination IP addresses\n",
    "    data = data.withColumn(\n",
    "        \"IPV4_SRC_ADDR_Subnet\",\n",
    "        concat_ws(\".\", split(col(\"IPV4_SRC_ADDR\"), \"\\\\.\")[0], split(col(\"IPV4_SRC_ADDR\"), \"\\\\.\")[1])\n",
    "    )\n",
    "\n",
    "    data = data.withColumn(\n",
    "        \"IPV4_DST_ADDR_Subnet\",\n",
    "        concat_ws(\".\", split(col(\"IPV4_DST_ADDR\"), \"\\\\.\")[0], split(col(\"IPV4_DST_ADDR\"), \"\\\\.\")[1])\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "train_data = add_subnet_columns(train_data)\n",
    "test_data = add_subnet_columns(test_data)\n",
    "\n",
    "# Show the new columns along with the original IP addresses\n",
    "train_data.select(\"IPV4_SRC_ADDR\", \"IPV4_SRC_ADDR_Subnet\", \"IPV4_DST_ADDR\", \"IPV4_DST_ADDR_Subnet\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count distinct values in IPV4_SRC_ADDR_Subnet\n",
    "distinct_src_subnet_count = train_data.select(countDistinct(\"IPV4_SRC_ADDR_Subnet\").alias(\"Distinct_SRC_Subnet_Count\"))\n",
    "\n",
    "# Count distinct values in IPV4_DST_ADDR_Subnet\n",
    "distinct_dst_subnet_count = train_data.select(countDistinct(\"IPV4_DST_ADDR_Subnet\").alias(\"Distinct_DST_Subnet_Count\"))\n",
    "\n",
    "# Show the results\n",
    "distinct_src_subnet_count.show(truncate=False)\n",
    "distinct_dst_subnet_count.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Source IP Dimensionality:** The modest reduction in unique source subnets compared to the full source IP count suggests that the network traffic originates from a diverse set of locations or devices, with slightly clustered but still quite spread out origins. This might imply that any predictive modeling using source subnets as a feature would still need to handle a relatively high number of categories, potentially requiring further techniques to manage dimensionality or enhance interpretability.\n",
    "\n",
    "- **Destination IP Dimensionality:** The more significant reduction in unique destination subnets points to a higher level of concentration of network traffic towards certain destination networks or servers. For modeling purposes, this could mean that destination subnet could be a more impactful feature, providing stronger predictive signals with fewer categories, thus improving model performance and simplicity.\n",
    "\n",
    "Given the results, for destination subnets, straightforward categorical encoding methods like one-hot encoding might be feasible given the reduced number of unique values. For source subnets, considering the still high number of unique categories, methods like feature hashing or embedding might be more appropriate to prevent models from becoming too complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afrom pyspark.ml.feature import StringIndexer, OneHotEncoder, FeatureHasher\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Define Indexers and Encoders for categorical variables\n",
    "attack_indexer = StringIndexer(inputCol=\"Attack\", outputCol=\"attack_index\")\n",
    "dst_subnet_indexer = StringIndexer(inputCol=\"IPV4_DST_ADDR_Subnet\", outputCol=\"dst_subnet_index\")\n",
    "dst_subnet_encoder = OneHotEncoder(inputCol=\"dst_subnet_index\", outputCol=\"dst_subnet_vec\")\n",
    "src_subnet_hasher = FeatureHasher(inputCols=[\"IPV4_SRC_ADDR_Subnet\"], outputCol=\"src_subnet_hashed\", numFeatures=1024)\n",
    "\n",
    "# Create a pipeline for encoding\n",
    "encoding_pipeline = Pipeline(stages=[\n",
    "    attack_indexer, \n",
    "    dst_subnet_indexer, \n",
    "    dst_subnet_encoder, \n",
    "    src_subnet_hasher\n",
    "])\n",
    "\n",
    "# Fit the encoding pipeline to the training data\n",
    "encoding_model = encoding_pipeline.fit(train_data)\n",
    "\n",
    "# Transform both training and test data\n",
    "encoded_train_data = encoding_model.transform(train_data)\n",
    "encoded_test_data = encoding_model.transform(test_data)\n",
    "\n",
    "# Show encoded features to verify\n",
    "encoded_train_data.select(\"Attack\", \"attack_index\", \"IPV4_SRC_ADDR_Subnet\", \"src_subnet_hashed\", \"IPV4_DST_ADDR_Subnet\", \"dst_subnet_vec\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scalling\n",
    "Feature scaling can play a crucial role in optimizing the performance of machine learning models, especially those sensitive to the scale of input data.\n",
    "Applying feature scaling to the right variables essential for improving model accuracy and efficiency. It ensures that each feature contributes equally to the decision-making process, preventing models from misinterpreting the data due to arbitrary feature scales. This leads to better, more reliable predictions in multiclass classification tasks.\n",
    "\n",
    "##### Numerical Variables with Different Scales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics summary for numerical variables candidates for scalling\n",
    "columns_of_interest = [\n",
    "    \"IN_BYTES\", \"OUT_BYTES\", \"IN_PKTS\", \"OUT_PKTS\", \n",
    "    \"FLOW_DURATION_MILLISECONDS\", \"SRC_TO_DST_SECOND_BYTES\", \n",
    "    \"DST_TO_SRC_SECOND_BYTES\", \"LONGEST_FLOW_PKT\", \"SHORTEST_FLOW_PKT\", \n",
    "    \"MIN_IP_PKT_LEN\", \"MAX_IP_PKT_LEN\", \"TCP_WIN_MAX_IN\", \"TCP_WIN_MAX_OUT\"\n",
    "]\n",
    "\n",
    "# Describe the selected columns\n",
    "stat_summary = train_data.select(columns_of_interest).describe()\n",
    "\n",
    "# Show the statistical summary\n",
    "stat_summary.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Assemble numerical features into vectors\n",
    "bytes_pkts_assembler = VectorAssembler(\n",
    "    inputCols=[\"IN_BYTES\", \"OUT_BYTES\", \"IN_PKTS\", \"OUT_PKTS\"],\n",
    "    outputCol=\"bytes_pkts_features\"\n",
    ")\n",
    "\n",
    "flow_duration_assembler = VectorAssembler(\n",
    "    inputCols=[\"FLOW_DURATION_MILLISECONDS\"],\n",
    "    outputCol=\"flow_duration_feature\"\n",
    ")\n",
    "\n",
    "throughput_assembler = VectorAssembler(\n",
    "    inputCols=[\"SRC_TO_DST_SECOND_BYTES\", \"DST_TO_SRC_SECOND_BYTES\"],\n",
    "    outputCol=\"throughput_features\"\n",
    ")\n",
    "\n",
    "pkt_len_assembler = VectorAssembler(\n",
    "    inputCols=[\"LONGEST_FLOW_PKT\", \"SHORTEST_FLOW_PKT\", \"MIN_IP_PKT_LEN\", \"MAX_IP_PKT_LEN\"],\n",
    "    outputCol=\"pkt_len_features\"\n",
    ")\n",
    "\n",
    "tcp_win_assembler = VectorAssembler(\n",
    "    inputCols=[\"TCP_WIN_MAX_IN\", \"TCP_WIN_MAX_OUT\"],\n",
    "    outputCol=\"tcp_win_features\"\n",
    ")\n",
    "\n",
    "# Apply StandardScaler to the assembled vectors\n",
    "bytes_pkts_scaler = StandardScaler(\n",
    "    inputCol=\"bytes_pkts_features\", \n",
    "    outputCol=\"scaled_bytes_pkts_features\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "flow_duration_scaler = StandardScaler(\n",
    "    inputCol=\"flow_duration_feature\", \n",
    "    outputCol=\"scaled_flow_duration\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "throughput_scaler = StandardScaler(\n",
    "    inputCol=\"throughput_features\", \n",
    "    outputCol=\"scaled_throughput_features\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "pkt_len_scaler = StandardScaler(\n",
    "    inputCol=\"pkt_len_features\", \n",
    "    outputCol=\"scaled_pkt_len_features\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "tcp_win_scaler = StandardScaler(\n",
    "    inputCol=\"tcp_win_features\", \n",
    "    outputCol=\"scaled_tcp_win_features\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "# Create a pipeline for scaling\n",
    "scaling_pipeline = Pipeline(stages=[\n",
    "    bytes_pkts_assembler, \n",
    "    bytes_pkts_scaler, \n",
    "    flow_duration_assembler, \n",
    "    flow_duration_scaler, \n",
    "    throughput_assembler, \n",
    "    throughput_scaler, \n",
    "    pkt_len_assembler, \n",
    "    pkt_len_scaler, \n",
    "    tcp_win_assembler, \n",
    "    tcp_win_scaler\n",
    "])\n",
    "\n",
    "# Fit the scalling pipeline to the encoded training data\n",
    "scalling_model = scaling_pipeline.fit(encoded_train_data)\n",
    "\n",
    "# Transform both encoded training and test data\n",
    "processed_train_data = scalling_model.transform(encoded_train_data)\n",
    "processed_test_data = scalling_model.transform(encoded_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------------+-----------+--------+--------+--------+-------+---------+--------+---------+----------------+----------------+--------------------------+-----------+------------+-------+-------+----------------+-----------------+--------------+--------------+-----------------------+-----------------------+----------------------+---------------------+-----------------------+----------------------+-------------------------+-------------------------+------------------------+-------------------------+-------------------------+--------------------------+---------------------------+--------------+---------------+---------+--------------+------------+--------------+--------------+--------------------+-----+--------+--------------------+--------------------+------------+----------------+--------------+------------------+--------------------+--------------------------+---------------------+--------------------+-------------------+--------------------------+--------------------+-----------------------+----------------+-----------------------+\n",
      "|IPV4_SRC_ADDR|L4_SRC_PORT|IPV4_DST_ADDR|L4_DST_PORT|PROTOCOL|L7_PROTO|IN_BYTES|IN_PKTS|OUT_BYTES|OUT_PKTS|TCP_FLAGS|CLIENT_TCP_FLAGS|SERVER_TCP_FLAGS|FLOW_DURATION_MILLISECONDS|DURATION_IN|DURATION_OUT|MIN_TTL|MAX_TTL|LONGEST_FLOW_PKT|SHORTEST_FLOW_PKT|MIN_IP_PKT_LEN|MAX_IP_PKT_LEN|SRC_TO_DST_SECOND_BYTES|DST_TO_SRC_SECOND_BYTES|RETRANSMITTED_IN_BYTES|RETRANSMITTED_IN_PKTS|RETRANSMITTED_OUT_BYTES|RETRANSMITTED_OUT_PKTS|SRC_TO_DST_AVG_THROUGHPUT|DST_TO_SRC_AVG_THROUGHPUT|NUM_PKTS_UP_TO_128_BYTES|NUM_PKTS_128_TO_256_BYTES|NUM_PKTS_256_TO_512_BYTES|NUM_PKTS_512_TO_1024_BYTES|NUM_PKTS_1024_TO_1514_BYTES|TCP_WIN_MAX_IN|TCP_WIN_MAX_OUT|ICMP_TYPE|ICMP_IPV4_TYPE|DNS_QUERY_ID|DNS_QUERY_TYPE|DNS_TTL_ANSWER|FTP_COMMAND_RET_CODE|Label|  Attack|IPV4_SRC_ADDR_Subnet|IPV4_DST_ADDR_Subnet|attack_index|dst_subnet_index|dst_subnet_vec| src_subnet_hashed| bytes_pkts_features|scaled_bytes_pkts_features|flow_duration_feature|scaled_flow_duration|throughput_features|scaled_throughput_features|    pkt_len_features|scaled_pkt_len_features|tcp_win_features|scaled_tcp_win_features|\n",
      "+-------------+-----------+-------------+-----------+--------+--------+--------+-------+---------+--------+---------+----------------+----------------+--------------------------+-----------+------------+-------+-------+----------------+-----------------+--------------+--------------+-----------------------+-----------------------+----------------------+---------------------+-----------------------+----------------------+-------------------------+-------------------------+------------------------+-------------------------+-------------------------+--------------------------+---------------------------+--------------+---------------+---------+--------------+------------+--------------+--------------+--------------------+-----+--------+--------------------+--------------------+------------+----------------+--------------+------------------+--------------------+--------------------------+---------------------+--------------------+-------------------+--------------------------+--------------------+-----------------------+----------------+-----------------------+\n",
      "| 192.168.1.32|      46696|192.168.1.180|      17288|       6|     0.0|      48|      1|        0|       0|        2|               2|               0|                         0|          0|           0|      0|      0|              48|               48|             0|            48|                   48.0|                    0.0|                     0|                    0|                      0|                     0|                   384000|                        0|                       1|                        0|                        0|                         0|                          0|          4096|              0|        0|             0|           0|             0|             0|                   0|    1|scanning|             192.168|             192.168|         1.0|             0.0| (6,[0],[1.0])|(1024,[906],[1.0])|  [48.0,0.0,1.0,0.0]|      [-0.3340954290867...|                [0.0]|[-0.5099706138072...|         [48.0,0.0]|      [-0.0734753712719...|[48.0,48.0,0.0,48.0]|   [-0.4919874575015...|    [4096.0,0.0]|   [-0.5363250954674...|\n",
      "| 192.168.1.30|      56607|192.168.1.194|      15632|       6|     0.0|      48|      1|       40|       1|       22|               2|              20|                         0|          0|           0|      0|      0|              48|               40|            40|            48|                   48.0|                   40.0|                     0|                    0|                      0|                     0|                   384000|                   320000|                       2|                        0|                        0|                         0|                          0|          4096|              0|        0|             0|           0|             0|             0|                   0|    1|scanning|             192.168|             192.168|         1.0|             0.0| (6,[0],[1.0])|(1024,[906],[1.0])| [48.0,40.0,1.0,1.0]|      [-0.3340954290867...|                [0.0]|[-0.5099706138072...|        [48.0,40.0]|      [-0.0734753712719...|[48.0,40.0,40.0,4...|   [-0.4919874575015...|    [4096.0,0.0]|   [-0.5363250954674...|\n",
      "| 192.168.1.31|      42103|192.168.1.190|       2004|       6|     0.0|      44|      1|       40|       1|       22|               2|              20|                         0|          0|           0|      0|      0|              44|               40|            40|            44|                   44.0|                   40.0|                     0|                    0|                      0|                     0|                   352000|                   320000|                       2|                        0|                        0|                         0|                          0|          1024|              0|        0|             0|           0|             0|             0|                   0|    0|  Benign|             192.168|             192.168|         0.0|             0.0| (6,[0],[1.0])|(1024,[906],[1.0])| [44.0,40.0,1.0,1.0]|      [-0.3375790522617...|                [0.0]|[-0.5099706138072...|        [44.0,40.0]|      [-0.0734771216598...|[44.0,40.0,40.0,4...|   [-0.4999859529900...|    [1024.0,0.0]|   [-0.7600385009822...|\n",
      "| 192.168.1.32|      52898|192.168.1.195|      52878|       6|     0.0|      48|      1|        0|       0|        2|               2|               0|                         0|          0|           0|      0|      0|              48|               48|             0|            48|                   48.0|                    0.0|                     0|                    0|                      0|                     0|                   384000|                        0|                       1|                        0|                        0|                         0|                          0|          4096|              0|        0|             0|           0|             0|             0|                   0|    1|scanning|             192.168|             192.168|         1.0|             0.0| (6,[0],[1.0])|(1024,[906],[1.0])|  [48.0,0.0,1.0,0.0]|      [-0.3340954290867...|                [0.0]|[-0.5099706138072...|         [48.0,0.0]|      [-0.0734753712719...|[48.0,48.0,0.0,48.0]|   [-0.4919874575015...|    [4096.0,0.0]|   [-0.5363250954674...|\n",
      "| 192.168.1.38|      59700|192.168.1.194|         80|       6|     7.0|     268|      5|      240|       4|       18|              18|              18|                   4294951|         16|          16|     64|     64|              60|               52|            52|            60|                  268.0|                  240.0|                     0|                    0|                      0|                     0|                   120000|                   112000|                       9|                        0|                        0|                         0|                          0|         29200|           5792|        0|             0|           0|             0|             0|                   0|    1|    ddos|             192.168|             192.168|         3.0|             0.0| (6,[0],[1.0])|(1024,[906],[1.0])|[268.0,240.0,5.0,...|      [-0.1424961544628...|          [4294951.0]|[1.9577713684699747]|      [268.0,240.0]|      [-0.0733790999356...|[60.0,52.0,52.0,6...|   [-0.4679919710358...|[29200.0,5792.0]|   [1.29183289022437...|\n",
      "+-------------+-----------+-------------+-----------+--------+--------+--------+-------+---------+--------+---------+----------------+----------------+--------------------------+-----------+------------+-------+-------+----------------+-----------------+--------------+--------------+-----------------------+-----------------------+----------------------+---------------------+-----------------------+----------------------+-------------------------+-------------------------+------------------------+-------------------------+-------------------------+--------------------------+---------------------------+--------------+---------------+---------+--------------+------------+--------------+--------------+--------------------+-----+--------+--------------------+--------------------+------------+----------------+--------------+------------------+--------------------+--------------------------+---------------------+--------------------+-------------------+--------------------------+--------------------+-----------------------+----------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "600\n",
      "+-------------+-----------+-------------+-----------+--------+--------+--------+-------+---------+--------+---------+----------------+----------------+--------------------------+-----------+------------+-------+-------+----------------+-----------------+--------------+--------------+-----------------------+-----------------------+----------------------+---------------------+-----------------------+----------------------+-------------------------+-------------------------+------------------------+-------------------------+-------------------------+--------------------------+---------------------------+--------------+---------------+---------+--------------+------------+--------------+--------------+--------------------+-----+--------+--------------------+--------------------+------------+----------------+--------------+------------------+--------------------+--------------------------+---------------------+--------------------+-------------------+--------------------------+--------------------+-----------------------+-----------------+-----------------------+\n",
      "|IPV4_SRC_ADDR|L4_SRC_PORT|IPV4_DST_ADDR|L4_DST_PORT|PROTOCOL|L7_PROTO|IN_BYTES|IN_PKTS|OUT_BYTES|OUT_PKTS|TCP_FLAGS|CLIENT_TCP_FLAGS|SERVER_TCP_FLAGS|FLOW_DURATION_MILLISECONDS|DURATION_IN|DURATION_OUT|MIN_TTL|MAX_TTL|LONGEST_FLOW_PKT|SHORTEST_FLOW_PKT|MIN_IP_PKT_LEN|MAX_IP_PKT_LEN|SRC_TO_DST_SECOND_BYTES|DST_TO_SRC_SECOND_BYTES|RETRANSMITTED_IN_BYTES|RETRANSMITTED_IN_PKTS|RETRANSMITTED_OUT_BYTES|RETRANSMITTED_OUT_PKTS|SRC_TO_DST_AVG_THROUGHPUT|DST_TO_SRC_AVG_THROUGHPUT|NUM_PKTS_UP_TO_128_BYTES|NUM_PKTS_128_TO_256_BYTES|NUM_PKTS_256_TO_512_BYTES|NUM_PKTS_512_TO_1024_BYTES|NUM_PKTS_1024_TO_1514_BYTES|TCP_WIN_MAX_IN|TCP_WIN_MAX_OUT|ICMP_TYPE|ICMP_IPV4_TYPE|DNS_QUERY_ID|DNS_QUERY_TYPE|DNS_TTL_ANSWER|FTP_COMMAND_RET_CODE|Label|  Attack|IPV4_SRC_ADDR_Subnet|IPV4_DST_ADDR_Subnet|attack_index|dst_subnet_index|dst_subnet_vec| src_subnet_hashed| bytes_pkts_features|scaled_bytes_pkts_features|flow_duration_feature|scaled_flow_duration|throughput_features|scaled_throughput_features|    pkt_len_features|scaled_pkt_len_features| tcp_win_features|scaled_tcp_win_features|\n",
      "+-------------+-----------+-------------+-----------+--------+--------+--------+-------+---------+--------+---------+----------------+----------------+--------------------------+-----------+------------+-------+-------+----------------+-----------------+--------------+--------------+-----------------------+-----------------------+----------------------+---------------------+-----------------------+----------------------+-------------------------+-------------------------+------------------------+-------------------------+-------------------------+--------------------------+---------------------------+--------------+---------------+---------+--------------+------------+--------------+--------------+--------------------+-----+--------+--------------------+--------------------+------------+----------------+--------------+------------------+--------------------+--------------------------+---------------------+--------------------+-------------------+--------------------------+--------------------+-----------------------+-----------------+-----------------------+\n",
      "| 192.168.1.32|      58592|192.168.1.195|         80|       6|     7.0|     661|     10|     2234|       8|       27|              27|              27|                   4294733|        234|         234|     64|     64|            1500|               40|            40|          1500|                  661.0|                 2234.0|                     0|                    0|                      0|                     0|                    16000|                    72000|                      15|                        0|                        2|                         0|                          1|         29200|          65535|        0|             0|           0|             0|             0|                   0|    1|password|             192.168|             192.168|         4.0|             0.0| (6,[0],[1.0])|(1024,[906],[1.0])|[661.0,2234.0,10....|      [0.19976982247883...|          [4294733.0]| [1.957646112616733]|     [661.0,2234.0]|      [-0.0732071243212...|[1500.0,40.0,40.0...|   [2.41146640484686...|[29200.0,65535.0]|   [1.29183289022437...|\n",
      "| 192.168.1.30|      41436|192.168.1.184|        443|       6|    91.0|     112|      2|      112|       2|       19|              18|              19|                   4294904|          0|          63|     64|     64|              60|               52|            52|            60|                  112.0|                  112.0|                     0|                    0|                      0|                     0|                   896000|                     8000|                       4|                        0|                        0|                         0|                          0|         29200|          28960|        0|             0|           0|             0|             0|                   0|    1|    ddos|             192.168|             192.168|         3.0|             0.0| (6,[0],[1.0])|(1024,[906],[1.0])|[112.0,112.0,2.0,...|      [-0.2783574582870...|          [4294904.0]|[1.9577443637676704]|      [112.0,112.0]|      [-0.0734473650649...|[60.0,52.0,52.0,6...|   [-0.4679919710358...|[29200.0,28960.0]|   [1.29183289022437...|\n",
      "| 192.168.1.30|      32374|192.168.1.180|      25720|       6|     0.0|      48|      1|        0|       0|        2|               2|               0|                         0|          0|           0|      0|      0|              48|               48|             0|            48|                   48.0|                    0.0|                     0|                    0|                      0|                     0|                   384000|                        0|                       1|                        0|                        0|                         0|                          0|          4096|              0|        0|             0|           0|             0|             0|                   0|    1|scanning|             192.168|             192.168|         1.0|             0.0| (6,[0],[1.0])|(1024,[906],[1.0])|  [48.0,0.0,1.0,0.0]|      [-0.3340954290867...|                [0.0]|[-0.5099706138072...|         [48.0,0.0]|      [-0.0734753712719...|[48.0,48.0,0.0,48.0]|   [-0.4919874575015...|     [4096.0,0.0]|   [-0.5363250954674...|\n",
      "| 192.168.1.35|      53904|52.28.231.150|         80|       6|   7.178|    4106|      8|     2132|       7|       27|              27|              27|                         0|          0|           0|     64|     64|            1500|               52|            52|          1500|                 4106.0|                 2132.0|                     0|                    0|                      0|                     0|                 32848000|                 17056000|                      10|                        0|                        1|                         1|                          3|         29200|          26847|        0|             0|           0|             0|             0|                   0|    1|     xss|             192.168|               52.28|         2.0|             3.0| (6,[3],[1.0])|(1024,[906],[1.0])|[4106.0,2132.0,8....|      [3.20004028192969...|                [0.0]|[-0.5099706138072...|    [4106.0,2132.0]|      [-0.0716996027146...|[1500.0,52.0,52.0...|   [2.41146640484686...|[29200.0,26847.0]|   [1.29183289022437...|\n",
      "| 192.168.1.30|      42453| 192.168.1.49|       5544|       6|     0.0|      44|      1|        0|       0|        2|               2|               0|                         0|          0|           0|      0|      0|              44|               44|             0|            44|                   44.0|                    0.0|                     0|                    0|                      0|                     0|                   352000|                        0|                       1|                        0|                        0|                         0|                          0|          1024|              0|        0|             0|           0|             0|             0|                   0|    0|  Benign|             192.168|             192.168|         0.0|             0.0| (6,[0],[1.0])|(1024,[906],[1.0])|  [44.0,0.0,1.0,0.0]|      [-0.3375790522617...|                [0.0]|[-0.5099706138072...|         [44.0,0.0]|      [-0.0734771216598...|[44.0,44.0,0.0,44.0]|   [-0.4999859529900...|     [1024.0,0.0]|   [-0.7600385009822...|\n",
      "+-------------+-----------+-------------+-----------+--------+--------+--------+-------+---------+--------+---------+----------------+----------------+--------------------------+-----------+------------+-------+-------+----------------+-----------------+--------------+--------------+-----------------------+-----------------------+----------------------+---------------------+-----------------------+----------------------+-------------------------+-------------------------+------------------------+-------------------------+-------------------------+--------------------------+---------------------------+--------------+---------------+---------+--------------+------------+--------------+--------------+--------------------+-----+--------+--------------------+--------------------+------------+----------------+--------------+------------------+--------------------+--------------------------+---------------------+--------------------+-------------------+--------------------------+--------------------+-----------------------+-----------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "processed_train_data.show(5)\n",
    "print(processed_train_data.count())\n",
    "\n",
    "processed_test_data.show(5)\n",
    "print(processed_test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
