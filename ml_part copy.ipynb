{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+------------------+--------------------+-------------------------+--------------------+------------------------+------------------------+-----------------------+--------------------------+------------------------+---------------------------+--------------------+\n",
      "|attack_index|     dst_subnet_vec| src_subnet_hashed| scaled_ttl_features|scaled_tcp_flags_features|scaled_flow_features|scaled_duration_features|scaled_pkt_size_features|scaled_tcp_win_features|scaled_throughput_features|scaled_protocol_features|scaled_l4_dst_port_features| scaled_dns_features|\n",
      "+------------+-------------------+------------------+--------------------+-------------------------+--------------------+------------------------+------------------------+-----------------------+--------------------------+------------------------+---------------------------+--------------------+\n",
      "|         0.0|(2831,[1018],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.8693157631485...|[-0.3676569242010...|    [-0.4758707225956...|    [1.68490859553789...|   [-0.7857763278409...|      [-0.0,-0.0,-0.166...|     [2.390132871319637]|       [-0.5476766864501...|[0.65839672359482...|\n",
      "|         0.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4667162378312...|    [-0.4758707225956...|    [0.30193573587770...|   [-0.7101779897555...|      [-0.0,-0.0,-0.191...|    [-0.411540796986748]|       [-0.4844249244232...|[-0.3451425426466...|\n",
      "|         1.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4667162378312...|    [-0.4758707225956...|    [-1.2347007748558...|   [-0.7101779897555...|      [-0.0,-0.0,-0.191...|    [-0.411540796986748]|       [-0.5245357979037...|[-0.3451425426466...|\n",
      "|         0.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4667162378312...|    [-0.4758707225956...|    [-1.2347007748558...|   [-0.7101779897555...|      [-0.0,-0.0,-0.191...|    [-0.411540796986748]|       [0.3996163536620361]|[-0.3451425426466...|\n",
      "|         1.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4584612950286...|    [-0.4758707225956...|    [0.30193573587770...|   [-0.4833829754995...|      [-0.0,-0.0,-0.188...|    [-0.411540796986748]|       [-0.3476563395526...|[-0.3451425426466...|\n",
      "|         3.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[1.17920440176065...|     [0.77966474770577...|[-0.4336964666211...|    [2.10152314261340...|    [0.76292668909777...|   [1.36995753162424...|      [-0.0,-0.0,-0.222...|    [-0.411540796986748]|       [-0.5245357979037...|[-0.3451425426466...|\n",
      "|         2.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.8693157631485...|[-0.3511470385959...|    [-0.4758707225956...|    [1.37758129339118...|   [-0.7857763278409...|      [-0.0,-0.0,-0.173...|     [2.390132871319637]|       [-0.5476766864501...|[2.08787739032491...|\n",
      "|         0.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4667162378312...|    [-0.4758707225956...|    [-1.2347007748558...|   [-0.7101779897555...|      [-0.0,-0.0,-0.191...|    [-0.411540796986748]|       [-0.4524430297398...|[-0.3451425426466...|\n",
      "|         0.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4667162378312...|    [-0.4758707225956...|    [-1.2347007748558...|   [-0.7101779897555...|      [-0.0,-0.0,-0.191...|    [-0.411540796986748]|       [0.05695319633990...|[-0.3451425426466...|\n",
      "|         0.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4584612950286...|    [-0.4758707225956...|    [-1.2347007748558...|   [-0.4833829754995...|      [-0.0,-0.0,-0.188...|    [-0.411540796986748]|       [1.2864464054952083]|[-0.3451425426466...|\n",
      "|         2.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[1.17920440176065...|     [1.60415500313293...|[2.53808294228475...|    [-0.4758707225956...|    [0.76292668909777...|   [1.36995753162424...|      [-0.0,-0.0,1.7125...|    [-0.411540796986748]|       [-0.546074624935388]|[-0.3451425426466...|\n",
      "|         5.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.8693157631485...|[-0.4109953739142...|    [-0.4758707225956...|    [1.49282903169620...|   [-0.7857763278409...|      [-0.0,-0.0,-0.170...|     [2.390132871319637]|       [-0.5476766864501...|[3.43464308063885...|\n",
      "|         0.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4667162378312...|    [-0.4758707225956...|    [-1.2347007748558...|   [-0.7101779897555...|      [-0.0,-0.0,-0.191...|    [-0.411540796986748]|       [-0.2001480089720...|[-0.3451425426466...|\n",
      "|         1.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4584612950286...|    [-0.4758707225956...|    [-1.2347007748558...|   [-0.4833829754995...|      [-0.0,-0.0,-0.188...|    [-0.411540796986748]|       [0.06508217513698...|[-0.3451425426466...|\n",
      "|         1.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4584612950286...|    [-0.4758707225956...|    [-1.2347007748558...|   [-0.4833829754995...|      [-0.0,-0.0,-0.188...|    [-0.411540796986748]|       [-0.1342854800322...|[-0.3451425426466...|\n",
      "|         0.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4667162378312...|    [-0.4758707225956...|    [0.30193573587770...|   [-0.7101779897555...|      [-0.0,-0.0,-0.191...|    [-0.411540796986748]|       [-0.2871340156620...|[-0.3451425426466...|\n",
      "|         2.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.8693157631485...|[-0.0704789833104...|    [-0.4758707225956...|    [1.37758129339118...|   [-0.7857763278409...|      [-0.0,-0.0,-0.173...|     [2.390132871319637]|       [-0.5476766864501...|[2.10357620411204...|\n",
      "|         0.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4667162378312...|    [-0.4758707225956...|    [-1.2347007748558...|   [-0.7101779897555...|      [-0.0,-0.0,-0.191...|    [-0.411540796986748]|       [-0.428293435795227]|[-0.3451425426466...|\n",
      "|         1.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.6860957063869...|[-0.4667162378312...|    [-0.4758707225956...|    [-1.2347007748558...|   [-0.7101779897555...|      [-0.0,-0.0,-0.191...|    [-0.411540796986748]|       [-0.5245357979037...|[-0.3451425426466...|\n",
      "|         5.0|   (2831,[0],[1.0])|(1024,[597],[0.0])|[-0.6995209701154...|     [-0.8693157631485...|[-0.4192503167167...|    [-0.4758707225956...|    [1.33916538062285...|   [-0.7857763278409...|      [-0.0,-0.0,-0.173...|     [2.390132871319637]|       [-0.5476766864501...|[3.17272466382242...|\n",
      "+------------+-------------------+------------------+--------------------+-------------------------+--------------------+------------------------+------------------------+-----------------------+--------------------------+------------------------+---------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import parquet file with pySpark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session\n",
    "spark = SparkSession.builder.appName(\"parquet\").getOrCreate()\n",
    "\n",
    "# Read parquet file\n",
    "df = spark.read.parquet(r\"./scaled_simplified_train_data.parquet\")\n",
    "\n",
    "# Show the data\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, FeatureHasher, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# OneHot encoding for destination subnet since higher cardinality\n",
    "dst_subnet_encoder = OneHotEncoder(inputCol=\"dst_subnet_index\", outputCol=\"dst_subnet_vec\")\n",
    "\n",
    "# Source address\n",
    "# Feature hashing for source subnet since lower cardinality\n",
    "src_subnet_hasher = FeatureHasher(inputCols=[\"src_subnet_index\"], outputCol=\"src_subnet_hashed\", numFeatures=1024)\n",
    "\n",
    "# Assemble numerical features for bytes and packets trasmitted\n",
    "trasimitted_in_features = [\"IN_BYTES\", \"IN_PKTS\"]\n",
    "trasmitted_out_features = [\"OUT_BYTES\", \"OUT_PKTS\"]\n",
    "retransimtted_in_features = [\"RETRANSMITTED_IN_BYTES\", \"RETRANSMITTED_IN_PKTS\"]\n",
    "retransimtted_out_features = [\"RETRANSMITTED_OUT_BYTES\", \"RETRANSMITTED_OUT_PKTS\"]\n",
    "throughput_in_features = [\"SRC_TO_DST_SECOND_BYTES\", \"SRC_TO_DST_AVG_THROUGHPUT\"]\n",
    "throughput_out_features = [\"DST_TO_SRC_AVG_THROUGHPUT\", \"DST_TO_SRC_SECOND_BYTES\"]\n",
    "ttl_features = [\"MIN_TTL\", \"MAX_TTL\"]\n",
    "tcp_flags_features = [\"CLIENT_TCP_FLAGS\", \"SERVER_TCP_FLAGS\", \"TCP_FLAGS\"]\n",
    "icmp_features = [\"ICMP_TYPE\", \"ICMP_IPV4_TYPE\"]\n",
    "flow_max_features = [\"LONGEST_FLOW_PKT\", \"MAX_IP_PKT_LEN\"]\n",
    "flow_min_features = [\"SHORTEST_FLOW_PKT\", \"MIN_IP_PKT_LEN\"]\n",
    "flow_duration_features = [\"FLOW_DURATION_MILLISECONDS\"]\n",
    "tcp_in_features = [\"TCP_WIN_MAX_IN\"]\n",
    "tcp_out_features = [\"TCP_WIN_MAX_OUT\"]\n",
    "duration_in_features = [\"DURATION_IN\"]\n",
    "duration_out_features = [\"DURATION_OUT\"]\n",
    "protocol_features = [\"PROTOCOL\"]\n",
    "l4_src_port_features = [\"L4_SRC_PORT\"]\n",
    "l4_dst_port_features = [\"L4_DST_PORT\"]\n",
    "dns_features = [\"DNS_QUERY_ID\", \"DNS_QUERY_TYPE\", \"DNS_TTL_ANSWER\"]\n",
    "ftp_features = [\"FTP_COMMAND_RET_CODE\"]\n",
    "l7_proto_features = [\"L7_PROTO\"]\n",
    "num_packets_by_size_features = [\"NUM_PKTS_UP_TO_128_BYTES\", \"NUM_PKTS_128_TO_256_BYTES\", \"NUM_PKTS_256_TO_512_BYTES\", \"NUM_PKTS_512_TO_1024_BYTES\", \"NUM_PKTS_1024_TO_1514_BYTES\"]\n",
    "\n",
    "\n",
    "\n",
    "# Assemble numerical features for flow duration\n",
    "flow_duration_assembler = VectorAssembler(\n",
    "    inputCols=[\"FLOW_DURATION_MILLISECONDS\"],\n",
    "    outputCol=\"flow_duration_feature\"\n",
    ")\n",
    "\n",
    "tcp__assembler = VectorAssembler(\n",
    "    inputCols=[\"TCP_WIN_MAX_IN\", \"TCP_WIN_MAX_OUT\"],\n",
    "    outputCol=\"tcp_win_features\",\n",
    ")\n",
    "\n",
    "# Apply StandardScaler to the assembled vectors\n",
    "bytes_pkts_scaler = StandardScaler(\n",
    "    inputCol=\"bytes_pkts_features\", \n",
    "    outputCol=\"scaled_bytes_pkts_features\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "flow_duration_scaler = StandardScaler(\n",
    "    inputCol=\"flow_duration_feature\", \n",
    "    outputCol=\"scaled_flow_duration\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "throughput_scaler = StandardScaler(\n",
    "    inputCol=\"throughput_features\", \n",
    "    outputCol=\"scaled_throughput_features\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "pkt_len_scaler = StandardScaler(\n",
    "    inputCol=\"pkt_len_features\", \n",
    "    outputCol=\"scaled_pkt_len_features\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "tcp_win_scaler = StandardScaler(\n",
    "    inputCol=\"tcp_win_features\", \n",
    "    outputCol=\"scaled_tcp_win_features\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "# Create a pipeline for scaling\n",
    "scaling_pipeline = Pipeline(stages=[\n",
    "    dst_subnet_encoder,\n",
    "    src_subnet_hasher,\n",
    "    bytes_pkts_assembler, \n",
    "    bytes_pkts_scaler, \n",
    "    flow_duration_assembler, \n",
    "    flow_duration_scaler, \n",
    "    throughput_assembler, \n",
    "    throughput_scaler, \n",
    "    pkt_len_assembler, \n",
    "    pkt_len_scaler, \n",
    "    tcp_win_assembler, \n",
    "    tcp_win_scaler\n",
    "])\n",
    "\n",
    "# Fit the scalling pipeline to the encoded training data\n",
    "scalling_model = scaling_pipeline.fit(encoded_train_data)\n",
    "\n",
    "# Transform both encoded training and test data\n",
    "processed_train_data = scalling_model.transform(encoded_train_data)\n",
    "processed_test_data = scalling_model.transform(encoded_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dst_subnet_vec', 'src_subnet_hashed', 'scaled_ttl_features', 'scaled_tcp_flags_features', 'scaled_flow_features', 'scaled_duration_features', 'scaled_pkt_size_features', 'scaled_tcp_win_features', 'scaled_throughput_features', 'scaled_protocol_features', 'scaled_l4_dst_port_features', 'scaled_dns_features']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Preparar os dados com VectorAssembler\n",
    "feature_columns = df.columns\n",
    "feature_columns.remove(\"attack_index\")\n",
    "print(feature_columns)\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df_assembled = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier, NaiveBayes, LogisticRegression, MultilayerPerceptronClassifier\n",
    "\n",
    "# Definir o Random Forest\n",
    "rf = RandomForestClassifier(labelCol=\"attack_index\", featuresCol=\"features\", numTrees=5)\n",
    "\n",
    "# Definir o Naive Bayes\n",
    "#nb = NaiveBayes(labelCol=\"attack_index\", featuresCol=\"features\")\n",
    "\n",
    "# Definir o Logistic Regression\n",
    "lr = LogisticRegression(labelCol=\"attack_index\", featuresCol=\"features\")\n",
    "\n",
    "# Configuração do Multilayer Perceptron\n",
    "# Obter o número de características\n",
    "def get_feature_count(df, feature_col=\"features\"):\n",
    "# Extrai os metadados da coluna de características e calcula a soma dos tamanhos dos atributos\n",
    "    attributes = df.schema[feature_col].metadata[\"ml_attr\"][\"attrs\"]\n",
    "    feature_count = sum(len(attrs) for attrs in attributes.values())\n",
    "    return feature_count\n",
    "input_layers = get_feature_count(df_assembled, \"features\")\n",
    "output_layers = df_assembled.select(\"attack_index\").distinct().count()\n",
    "hidden_layers = [input_layers // 2, output_layers]\n",
    "mlp = MultilayerPerceptronClassifier(\n",
    "    labelCol=\"attack_index\", \n",
    "    featuresCol=\"features\", \n",
    "    layers=hidden_layers, \n",
    "    maxIter=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1292/129384374.py\", line 5, in <module>\n",
      "    model_lr = lr.fit(df_assembled)\n",
      "               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/pyspark/ml/base.py\", line 205, in fit\n",
      "    return self._fit(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/pyspark/ml/wrapper.py\", line 381, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/pyspark/ml/wrapper.py\", line 378, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py\", line 179, in deco\n",
      "    return f(*a, **kw)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <exception str() failed>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#model_nb = nb.fit(df_assembled)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# logistic regression\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model_lr \u001b[38;5;241m=\u001b[39m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_assembled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Multilayer Perceptron\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/pyspark/ml/wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/pyspark/ml/wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(111, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2179\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2176\u001b[0m         traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m   2177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2179\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_showtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_pdb:\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[1;32m   2182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/ipykernel/zmqshell.py:559\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    553\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    554\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    556\u001b[0m exc_content \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m\"\u001b[39m: stb,\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(etype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    560\u001b[0m }\n\u001b[1;32m    562\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayhook\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/protocol.py:471\u001b[0m, in \u001b[0;36mPy4JJavaError.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    470\u001b[0m     gateway_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_exception\u001b[38;5;241m.\u001b[39m_gateway_client\n\u001b[0;32m--> 471\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m get_return_value(answer, gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;66;03m# Note: technically this should return a bytestring 'str' rather than\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# unicodes in Python 2; however, it can return unicodes for now.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "model_rf = rf.fit(df_assembled)\n",
    "#model_nb = nb.fit(df_assembled)\n",
    "# logistic regression\n",
    "model_lr = lr.fit(df_assembled)\n",
    "# Multilayer Perceptron\n",
    "model_mlp = mlp.fit(df_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Avaliador\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"attack_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Avaliar Random Forest\n",
    "accuracy_rf = evaluator.evaluate(model_rf.transform(df_assembled))\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf}\")\n",
    "\n",
    "# Avaliar Naive Bayes\n",
    "#accuracy_nb = evaluator.evaluate(model_nb.transform(df_assembled))\n",
    "#print(f\"Naive Bayes Accuracy: {accuracy_nb}\")\n",
    "\n",
    "# Avaliar Logistic Regression\n",
    "accuracy_lr = evaluator.evaluate(model_lr.transform(df_assembled))\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_lr}\")\n",
    "\n",
    "# Avaliar Multilayer Perceptron\n",
    "accuracy_mlp = evaluator.evaluate(model_mlp.transform(df_assembled))\n",
    "print(f\"Multilayer Perceptron Accuracy: {accuracy_mlp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
